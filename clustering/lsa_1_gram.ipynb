{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melod\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\melod\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open preprocessed reviews as a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open preprocessed data\n",
    "df = pd.read_csv('../data/processed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ABRASIVE CLEANERS', 'AIR FRESHENER', 'BATHROOM CLEANERS', 'BATHROOM CLEANERS DAILY SHOWER CLEANERS', 'BATHROOM CLEANERS GENERAL BATHROOM CLEANERS', 'BATHROOM CLEANERS LIMESCALE/HARDWATER CLEANERS', 'BATHROOM CLEANERS MILDEW CLEANERS', 'BODY CARE', 'BODY CARE BAR SOAP', 'BODY CARE BATH SOAP', 'BODY CARE BODY LOTION', 'BODY CARE BODY OIL', 'BODY CARE BODY TOOLS', 'BODY CARE BODY WASH', 'BODY CARE BODY WIPES', 'BODY CARE DEODORANT', 'BODY CARE FOOT CARE', 'BODY CARE HAIR REMOVAL', 'BODY CARE HAND CARE', 'CONSUMABLE TOOLS', 'CONSUMABLE TOOLS CLEANING CLOTHS', 'CONSUMABLE TOOLS CONSUMABLE SCRUBBERS', 'CONSUMABLE TOOLS SOAP PADS/STEEL WOOL', 'CONSUMABLE TOOLS SPONGES', 'CORE GIFTS', 'CORE GIFTS EVERYDAY KITS', 'CORE GIFTS HOLIDAY KITS', 'DILUTABLES', 'DILUTABLES NATURAL/CONCENTRATED', 'DILUTABLES PINE/DISINFECTING DILUTABLES', 'DILUTABLES SCENTED/NON-DISINFECTING DILUTABLES', 'DISH CARE', 'DISH CARE LIQUID DISH DETERGENT', 'DRAIN CARE', 'FACE CARE', 'FACE CARE ACNE TREATMENTS', 'FACE CARE FACE CARE TOOLS', 'FACE CARE FACE MASKS', 'FACE CARE FACIAL CLEANSERS', 'FACE CARE FACIAL MOISTURIZERS', 'FACE CARE FACIAL PRIMER', 'FACE CARE FACIAL TOWELETTES', 'FACE CARE FACIAL TREATMENTS', 'FACE CARE HAIR REMOVAL', 'FLOOR CLEANERS', 'FLOOR CLEANERS CARPET', 'FLOOR CLEANERS CONVENIENCE', 'FLOOR CLEANERS SPECIALTY', 'HAIR CARE', 'HAIR CARE CONDITIONER', 'HAIR CARE HAIR TREATMENTS', 'HAIR CARE SHAMPOO', 'LIP CARE', 'LIP CARE LIP BALM', 'LIP CARE LIP BUTTERS', 'LIP CARE LIP OILS', 'LIP CARE LIP TREATMENT', 'LIP CARE PREMIUM LIP CARE', \"MEN'S CARE\", \"MEN'S CARE BEARD TREATMENT\", \"MEN'S CARE BODY WASH\", \"MEN'S CARE FACIAL CLEANSERS\", \"MEN'S CARE FACIAL MOISTURIZER & AFTERSHAVE\", \"MEN'S CARE SHAVE\", 'MOISTURE ABSORBER', 'ODOR CONTROLLING', 'ODOR CONTROLLING AIR FRESHENERS', 'ODOR CONTROLLING AIR ODOR REMOVERS', 'ODOR CONTROLLING DISINFECTING SPRAYS', 'ODOR CONTROLLING FABRIC REFRESHERS', 'SPECIALIZED SPRAYS', 'SPECIALIZED SPRAYS OVEN/SPECIALTY', 'SPRAY CLEANERS', 'SPRAY CLEANERS ALL PURPOSE CLEANERS', 'SPRAY CLEANERS BLEACH CLEANERS', 'SPRAY CLEANERS GLASS + SURFACE CLEANERS', 'SUNCARE & FIRST AID', 'SUNCARE & FIRST AID AFTER SUN', 'SUNCARE & FIRST AID FIRST AID OINTMENT', 'SUNCARE & FIRST AID SUNCARE', 'TOILET BOWL CLEANERS', 'TOILET BOWL CLEANERS AUTOMATIC TB CLEANERS', 'TOILET BOWL CLEANERS CONVENIENCE TB CLEANERS', 'TOILET BOWL CLEANERS MANUAL TB CLEANERS', 'WIPES', 'WIPES COMPOSTABLE WIPES', 'WIPES DISINFECTING WIPES', 'WIPES NATURAL WIPES', 'WIPES OTHER WIPES', 'WOOD/FURNITURE/DUST', 'WOOD/FURNITURE/DUST CONVENIENCE WOOD/FURN/DUST', 'WOOD/FURNITURE/DUST FURNITURE WIPES', 'WOOD/FURNITURE/DUST POLISH', 'WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group reviews by subcategory and convert to dictionary\n",
    "grouped = df.groupby('subcategory')['review_text'].apply(list).to_dict()\n",
    "grouped.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lsa pipeline\n",
    "def create_components(n_topics):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                 use_idf=True, \n",
    "                                 ngram_range=(1, 1),\n",
    "                                 smooth_idf=True)\n",
    "    svd_model = TruncatedSVD(n_components=n_topics,        \n",
    "                             algorithm='randomized',\n",
    "                             n_iter=20)\n",
    "    svd_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                                ('svd', svd_model)])\n",
    "    return svd_transformer, vectorizer, svd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of first 2 subcategories\n",
    "groups = {k: grouped[k] for k in list(grouped)[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/sklearn/decomposition/_truncated_svd.py:275: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>top_words</th>\n",
       "      <th>sample_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>0</td>\n",
       "      <td>[clean, great, use, product, work, sink, good,...</td>\n",
       "      <td>[product work great for what i use it for, ive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, year, comet, product, love, ive, good, j...</td>\n",
       "      <td>[ive use comet for year, how be use this produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>2</td>\n",
       "      <td>[great, work, product, price, year, good, job,...</td>\n",
       "      <td>[work on almost everything great product, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>3</td>\n",
       "      <td>[good, clean, smell, bathroom, comet, price, w...</td>\n",
       "      <td>[work good for clean my bathroom, i love the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>4</td>\n",
       "      <td>[good, product, stainless, steel, price, pot, ...</td>\n",
       "      <td>[very very good product, good price good produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>10</td>\n",
       "      <td>[wood, love, cleaner, best, product, surface, ...</td>\n",
       "      <td>[best wood cleaner i have ever use, love how i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>11</td>\n",
       "      <td>[cleaner, best, smell, like, favorite, pledge,...</td>\n",
       "      <td>[love the smell of this cleaner, murphy be alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>12</td>\n",
       "      <td>[smell, use, nice, easy, work, year, receive, ...</td>\n",
       "      <td>[easy to use clean well smell nice, smell so g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>13</td>\n",
       "      <td>[make, surface, look, spray, wood, easy, good,...</td>\n",
       "      <td>[make wood look wonderful and make the house s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>14</td>\n",
       "      <td>[leave, surface, wood, shine, residue, nice, h...</td>\n",
       "      <td>[its a good product leave the surface nice and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1377 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     subcategory topic_number  \\\n",
       "0                              ABRASIVE CLEANERS            0   \n",
       "1                              ABRASIVE CLEANERS            1   \n",
       "2                              ABRASIVE CLEANERS            2   \n",
       "3                              ABRASIVE CLEANERS            3   \n",
       "4                              ABRASIVE CLEANERS            4   \n",
       "...                                          ...          ...   \n",
       "1372  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           10   \n",
       "1373  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           11   \n",
       "1374  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           12   \n",
       "1375  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           13   \n",
       "1376  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           14   \n",
       "\n",
       "                                              top_words  \\\n",
       "0     [clean, great, use, product, work, sink, good,...   \n",
       "1     [use, year, comet, product, love, ive, good, j...   \n",
       "2     [great, work, product, price, year, good, job,...   \n",
       "3     [good, clean, smell, bathroom, comet, price, w...   \n",
       "4     [good, product, stainless, steel, price, pot, ...   \n",
       "...                                                 ...   \n",
       "1372  [wood, love, cleaner, best, product, surface, ...   \n",
       "1373  [cleaner, best, smell, like, favorite, pledge,...   \n",
       "1374  [smell, use, nice, easy, work, year, receive, ...   \n",
       "1375  [make, surface, look, spray, wood, easy, good,...   \n",
       "1376  [leave, surface, wood, shine, residue, nice, h...   \n",
       "\n",
       "                                         sample_reviews  \n",
       "0     [product work great for what i use it for, ive...  \n",
       "1     [ive use comet for year, how be use this produ...  \n",
       "2     [work on almost everything great product, have...  \n",
       "3     [work good for clean my bathroom, i love the s...  \n",
       "4     [very very good product, good price good produ...  \n",
       "...                                                 ...  \n",
       "1372  [best wood cleaner i have ever use, love how i...  \n",
       "1373  [love the smell of this cleaner, murphy be alw...  \n",
       "1374  [easy to use clean well smell nice, smell so g...  \n",
       "1375  [make wood look wonderful and make the house s...  \n",
       "1376  [its a good product leave the surface nice and...  \n",
       "\n",
       "[1377 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each subcategory, fit the pipeline to the reviews and save results to lsa_df with columns: subcategory, topic_number, top_words, sample_reviews\n",
    "lsa_df = pd.DataFrame(columns=['subcategory', 'topic_number', 'top_words', 'sample_reviews'])\n",
    "\n",
    "for subcategory, reviews in grouped.items():\n",
    "    reviews = df[df['subcategory'] == subcategory]['review_text']\n",
    "    n_topics = int(min(15, len(reviews)))\n",
    "    # if n_topics >= 2:\n",
    "    svd_transformer, vectorizer, svd_model = create_components(n_topics)\n",
    "    svd_matrix = svd_transformer.fit_transform(reviews)\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for i, topic in enumerate(svd_model.components_):\n",
    "        top_words = [terms[j] for j in topic.argsort()[:-10 - 1:-1]]\n",
    "        n_samples = min(5, len(reviews))\n",
    "        rep_reviews = reviews.iloc[np.argsort(svd_matrix[:,i])[::-1][:3]].values\n",
    "        new_row = pd.DataFrame({'subcategory': [subcategory], 'topic_number': [i], 'top_words': [top_words], 'sample_reviews': [rep_reviews]})\n",
    "        lsa_df = pd.concat([lsa_df, new_row], ignore_index=True)\n",
    "\n",
    "lsa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lsa_df to csv\n",
    "lsa_df.to_csv('outputs/lsa_1gram_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster similar topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'clean great use product work sink good love year comet',\n",
       " 1: 'use year comet product love ive good job ajax cleanser',\n",
       " 2: 'great work product price year good job value wonder ive',\n",
       " 3: 'good clean smell bathroom comet price work love like toilet',\n",
       " 4: 'good product stainless steel price pot pan excellent job really',\n",
       " 5: 'best work cleaner comet cleanser good stain like ive water',\n",
       " 6: 'best cleaner great product bathroom price cleaning kitchen job excellent',\n",
       " 7: 'comet great stainless steel like best price love cleaner pot',\n",
       " 8: 'love best stain product smell water remove hard cleaner comet',\n",
       " 9: 'clean best like product pot cleaner pan thing scratch really',\n",
       " 10: 'bathroom work kitchen product best use cleaning pot pan smell',\n",
       " 11: 'cleaner love year smell good use stuff great tub clean',\n",
       " 12: 'bathroom job cleanser like bar keeper friend kitchen scrub cleaning',\n",
       " 13: 'cleaner like product scrub kitchen sink job comet ajax excellent',\n",
       " 14: 'like cleanser sink smell tub product new scrub look best'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove space between 2 gram words in top_words so that when vectorized, they are treated as one entity\n",
    "lsa_df['top_words'] = lsa_df['top_words'].apply(lambda x: [word.replace(' ', '') for word in x])\n",
    "\n",
    "# create dict of subcategories and array of top words joined to one string for each topic\n",
    "lsa_dict = {}\n",
    "for subcategory in lsa_df['subcategory'].unique():\n",
    "    sub_df = lsa_df[lsa_df['subcategory'] == subcategory]\n",
    "    sub_dict = {}\n",
    "    for topic in sub_df['topic_number']:\n",
    "        topic_df = sub_df[sub_df['topic_number'] == topic]\n",
    "        sub_dict[topic] = ' '.join(topic_df['top_words'].values[0])\n",
    "    lsa_dict[subcategory] = sub_dict\n",
    "lsa_dict['ABRASIVE CLEANERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster top words representations for each subcategory\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "n_clusters = 10\n",
    "\n",
    "# kmeans applied to a subcategory, return cluster labels\n",
    "def apply_kmeans(topics_dict, vectorizer, n_clusters):\n",
    "    if len(topics_dict) > n_clusters:\n",
    "        topics_vectorized = vectorizer.fit_transform(topics_dict.values())\n",
    "        kmeans_model = KMeans(n_clusters=n_clusters, random_state=12)\n",
    "        cluster_labels = kmeans_model.fit_predict(topics_vectorized)\n",
    "        return cluster_labels\n",
    "    return None\n",
    "\n",
    "# merge topics in subcategory with the same cluster labels\n",
    "def merge_topics(topics_dict, cluster_labels):\n",
    "    merged_topics = {}\n",
    "    for i in range(len(cluster_labels)):\n",
    "        if cluster_labels[i] not in merged_topics:\n",
    "            merged_topics[cluster_labels[i]] = topics_dict[i]\n",
    "        else:\n",
    "            merged_topics[cluster_labels[i]] += ' ' + topics_dict[i]\n",
    "    return merged_topics\n",
    "\n",
    "# remove duplicate words in merged topics\n",
    "def remove_duplicates(merged_topics):\n",
    "    for label, words in merged_topics.items():\n",
    "        merged_topics[label] = ' '.join(list(set(words.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int32(1): 'comet product work sink cleanser smell year job cleaner love use tub great clean ive stuff good ajax',\n",
       " np.int32(0): 'work product price year job value great ive good wonder',\n",
       " np.int32(6): 'comet work smell price like bathroom love clean good toilet',\n",
       " np.int32(3): 'comet really excellent product price job like cleaner steel love pan great stainless best good pot',\n",
       " np.int32(4): 'comet remove work stain cleanser product smell like cleaner love ive hard best good water',\n",
       " np.int32(7): 'excellent product work smell price job cleaner bathroom cleaning kitchen use great pan best pot',\n",
       " np.int32(8): 'really product like cleaner pan thing clean scratch best pot',\n",
       " np.int32(5): 'bar cleanser job like keeper bathroom friend kitchen cleaning scrub',\n",
       " np.int32(2): 'comet excellent product sink like job cleaner kitchen scrub ajax',\n",
       " np.int32(9): 'product smell sink cleanser like look tub scrub best new'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply kmeans to each subcategory and merge topics with the same cluster labels\n",
    "\n",
    "clustered_dict = {}\n",
    "for subcategory, topics_dict in lsa_dict.items():\n",
    "    cluster_labels = apply_kmeans(topics_dict, vectorizer, n_clusters)\n",
    "    if cluster_labels is not None:\n",
    "        merged_topics = merge_topics(topics_dict, cluster_labels)\n",
    "        remove_duplicates(merged_topics)\n",
    "        clustered_dict[subcategory] = merged_topics\n",
    "    else:\n",
    "        clustered_dict[subcategory] = topics_dict\n",
    "\n",
    "clustered_dict['ABRASIVE CLEANERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clustered_dict to csv\n",
    "clustered_df = pd.DataFrame(columns=['subcategory', 'topic_number', 'top_words'])\n",
    "for subcategory, topics_dict in clustered_dict.items():\n",
    "    for topic, words in topics_dict.items():\n",
    "        new_row = pd.DataFrame({'subcategory': [subcategory], 'topic_number': [topic], 'top_words': [words]})\n",
    "        clustered_df = pd.concat([clustered_df, new_row], ignore_index=True)\n",
    "clustered_df.to_csv('outputs/lsa_1gram_clustered_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'work small dry come box'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_dict['BODY CARE HAIR REMOVAL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_processes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open preprocessed reviews as a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open preprocessed data\n",
    "df = pd.read_csv('../data/processed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ABRASIVE CLEANERS', 'AIR FRESHENER', 'BATHROOM CLEANERS', 'BATHROOM CLEANERS DAILY SHOWER CLEANERS', 'BATHROOM CLEANERS GENERAL BATHROOM CLEANERS', 'BATHROOM CLEANERS LIMESCALE/HARDWATER CLEANERS', 'BATHROOM CLEANERS MILDEW CLEANERS', 'BODY CARE', 'BODY CARE BAR SOAP', 'BODY CARE BATH SOAP', 'BODY CARE BODY LOTION', 'BODY CARE BODY OIL', 'BODY CARE BODY TOOLS', 'BODY CARE BODY WASH', 'BODY CARE BODY WIPES', 'BODY CARE DEODORANT', 'BODY CARE FOOT CARE', 'BODY CARE HAIR REMOVAL', 'BODY CARE HAND CARE', 'CONSUMABLE TOOLS', 'CONSUMABLE TOOLS CLEANING CLOTHS', 'CONSUMABLE TOOLS CONSUMABLE SCRUBBERS', 'CONSUMABLE TOOLS SOAP PADS/STEEL WOOL', 'CONSUMABLE TOOLS SPONGES', 'CORE GIFTS', 'CORE GIFTS EVERYDAY KITS', 'CORE GIFTS HOLIDAY KITS', 'DILUTABLES', 'DILUTABLES NATURAL/CONCENTRATED', 'DILUTABLES PINE/DISINFECTING DILUTABLES', 'DILUTABLES SCENTED/NON-DISINFECTING DILUTABLES', 'DISH CARE', 'DISH CARE LIQUID DISH DETERGENT', 'DRAIN CARE', 'FACE CARE', 'FACE CARE ACNE TREATMENTS', 'FACE CARE FACE CARE TOOLS', 'FACE CARE FACE MASKS', 'FACE CARE FACIAL CLEANSERS', 'FACE CARE FACIAL MOISTURIZERS', 'FACE CARE FACIAL PRIMER', 'FACE CARE FACIAL TOWELETTES', 'FACE CARE FACIAL TREATMENTS', 'FACE CARE HAIR REMOVAL', 'FLOOR CLEANERS', 'FLOOR CLEANERS CARPET', 'FLOOR CLEANERS CONVENIENCE', 'FLOOR CLEANERS SPECIALTY', 'HAIR CARE', 'HAIR CARE CONDITIONER', 'HAIR CARE HAIR TREATMENTS', 'HAIR CARE SHAMPOO', 'LIP CARE', 'LIP CARE LIP BALM', 'LIP CARE LIP BUTTERS', 'LIP CARE LIP OILS', 'LIP CARE LIP TREATMENT', 'LIP CARE PREMIUM LIP CARE', \"MEN'S CARE\", \"MEN'S CARE BEARD TREATMENT\", \"MEN'S CARE BODY WASH\", \"MEN'S CARE FACIAL CLEANSERS\", \"MEN'S CARE FACIAL MOISTURIZER & AFTERSHAVE\", \"MEN'S CARE SHAVE\", 'MOISTURE ABSORBER', 'ODOR CONTROLLING', 'ODOR CONTROLLING AIR FRESHENERS', 'ODOR CONTROLLING AIR ODOR REMOVERS', 'ODOR CONTROLLING DISINFECTING SPRAYS', 'ODOR CONTROLLING FABRIC REFRESHERS', 'SPECIALIZED SPRAYS', 'SPECIALIZED SPRAYS OVEN/SPECIALTY', 'SPRAY CLEANERS', 'SPRAY CLEANERS ALL PURPOSE CLEANERS', 'SPRAY CLEANERS BLEACH CLEANERS', 'SPRAY CLEANERS GLASS + SURFACE CLEANERS', 'SUNCARE & FIRST AID', 'SUNCARE & FIRST AID AFTER SUN', 'SUNCARE & FIRST AID FIRST AID OINTMENT', 'SUNCARE & FIRST AID SUNCARE', 'TOILET BOWL CLEANERS', 'TOILET BOWL CLEANERS AUTOMATIC TB CLEANERS', 'TOILET BOWL CLEANERS CONVENIENCE TB CLEANERS', 'TOILET BOWL CLEANERS MANUAL TB CLEANERS', 'WIPES', 'WIPES COMPOSTABLE WIPES', 'WIPES DISINFECTING WIPES', 'WIPES NATURAL WIPES', 'WIPES OTHER WIPES', 'WOOD/FURNITURE/DUST', 'WOOD/FURNITURE/DUST CONVENIENCE WOOD/FURN/DUST', 'WOOD/FURNITURE/DUST FURNITURE WIPES', 'WOOD/FURNITURE/DUST POLISH', 'WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group reviews by subcategory and convert to dictionary\n",
    "grouped_dict = df.groupby('subcategory')['review_text'].apply(list).to_dict()\n",
    "grouped_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lsa pipeline\n",
    "def create_components(n_topics):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                 use_idf=True, \n",
    "                                 ngram_range=(1, 2),\n",
    "                                 smooth_idf=True)\n",
    "    svd_model = TruncatedSVD(n_components=n_topics,        \n",
    "                             algorithm='randomized',\n",
    "                             n_iter=20)\n",
    "    svd_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                                ('svd', svd_model)])\n",
    "    return svd_transformer, vectorizer, svd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of first 2 subcategories\n",
    "groups = {k: grouped_dict[k] for k in list(grouped_dict)[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(reviews))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# get representative 3 reviews for each topic\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m rep_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mreviews\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvd_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: [subcategory], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_number\u001b[39m\u001b[38;5;124m'\u001b[39m: [i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_words\u001b[39m\u001b[38;5;124m'\u001b[39m: [top_words], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m: [rep_reviews]})\n\u001b[1;32m     19\u001b[0m lsa_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([lsa_df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# for each subcategory, fit the pipeline to the reviews and save results to lsa_df with columns: subcategory, topic_number, top_words, sample_reviews\n",
    "lsa_df = pd.DataFrame(columns=['subcategory', 'topic_number', 'top_words', 'sample_reviews'])\n",
    "\n",
    "for subcategory, reviews in grouped_dict.items():\n",
    "    # change grouped_dict to df\n",
    "    reviews = pd.DataFrame(reviews)\n",
    "    n_topics = int(min(15, len(reviews)))\n",
    "    # if n_topics >= 2:\n",
    "    svd_transformer, vectorizer, svd_model = create_components(n_topics)\n",
    "    svd_matrix = svd_transformer.fit_transform(reviews)\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for i, topic in enumerate(svd_model.components_):\n",
    "        top_words = [terms[j] for j in topic.argsort()[:-10 - 1:-1]]\n",
    "        n_samples = min(5, len(reviews))\n",
    "        # get representative 3 reviews for each topic\n",
    "        rep_reviews = \n",
    "            \n",
    "        new_row = pd.DataFrame({'subcategory': [subcategory], 'topic_number': [i], 'top_words': [top_words], 'sample_reviews': [rep_reviews]})\n",
    "        \n",
    "        lsa_df = pd.concat([lsa_df, new_row], ignore_index=True)\n",
    "\n",
    "lsa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/sklearn/decomposition/_truncated_svd.py:275: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>top_words</th>\n",
       "      <th>sample_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>0</td>\n",
       "      <td>[clean, great, use, product, work, sink, work ...</td>\n",
       "      <td>[this product work great on stainless steel si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, year, use year, comet, product, ive, ive...</td>\n",
       "      <td>[i have use this for many year, good product h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>2</td>\n",
       "      <td>[great, work, work great, great product, produ...</td>\n",
       "      <td>[have always work great, work on almost everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>3</td>\n",
       "      <td>[clean, bathroom, clean bathroom, kitchen, sme...</td>\n",
       "      <td>[clean what you put in on, cant clean without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABRASIVE CLEANERS</td>\n",
       "      <td>4</td>\n",
       "      <td>[good, product, good product, price, good pric...</td>\n",
       "      <td>[very very good product, good price good produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>10</td>\n",
       "      <td>[clean, product, great product, surface, clean...</td>\n",
       "      <td>[love how it clean my wood floor, i love this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>11</td>\n",
       "      <td>[make, like, look, furniture, shine, make floo...</td>\n",
       "      <td>[make my floor look new again, this make my fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>12</td>\n",
       "      <td>[cleaner, hardwood, hardwood floor, best, furn...</td>\n",
       "      <td>[best hardwood floor cleaner, best cleaner for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>13</td>\n",
       "      <td>[furniture, clean, leave, wood furniture, leat...</td>\n",
       "      <td>[i use on my leather and wood furniture work g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER</td>\n",
       "      <td>14</td>\n",
       "      <td>[leave, wood floor, smell, nice, residue, does...</td>\n",
       "      <td>[smell be nice and put shine on wood floor, gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1377 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     subcategory topic_number  \\\n",
       "0                              ABRASIVE CLEANERS            0   \n",
       "1                              ABRASIVE CLEANERS            1   \n",
       "2                              ABRASIVE CLEANERS            2   \n",
       "3                              ABRASIVE CLEANERS            3   \n",
       "4                              ABRASIVE CLEANERS            4   \n",
       "...                                          ...          ...   \n",
       "1372  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           10   \n",
       "1373  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           11   \n",
       "1374  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           12   \n",
       "1375  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           13   \n",
       "1376  WOOD/FURNITURE/DUST WOOD/FURNITURE CLEANER           14   \n",
       "\n",
       "                                              top_words  \\\n",
       "0     [clean, great, use, product, work, sink, work ...   \n",
       "1     [use, year, use year, comet, product, ive, ive...   \n",
       "2     [great, work, work great, great product, produ...   \n",
       "3     [clean, bathroom, clean bathroom, kitchen, sme...   \n",
       "4     [good, product, good product, price, good pric...   \n",
       "...                                                 ...   \n",
       "1372  [clean, product, great product, surface, clean...   \n",
       "1373  [make, like, look, furniture, shine, make floo...   \n",
       "1374  [cleaner, hardwood, hardwood floor, best, furn...   \n",
       "1375  [furniture, clean, leave, wood furniture, leat...   \n",
       "1376  [leave, wood floor, smell, nice, residue, does...   \n",
       "\n",
       "                                         sample_reviews  \n",
       "0     [this product work great on stainless steel si...  \n",
       "1     [i have use this for many year, good product h...  \n",
       "2     [have always work great, work on almost everyt...  \n",
       "3     [clean what you put in on, cant clean without ...  \n",
       "4     [very very good product, good price good produ...  \n",
       "...                                                 ...  \n",
       "1372  [love how it clean my wood floor, i love this ...  \n",
       "1373  [make my floor look new again, this make my fl...  \n",
       "1374  [best hardwood floor cleaner, best cleaner for...  \n",
       "1375  [i use on my leather and wood furniture work g...  \n",
       "1376  [smell be nice and put shine on wood floor, gr...  \n",
       "\n",
       "[1377 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lsa_df = pd.DataFrame(columns=['subcategory', 'topic_number', 'top_words', 'sample_reviews'])\n",
    "\n",
    "for subcategory, reviews in grouped_dict.items():\n",
    "    # change grouped_dict to df\n",
    "    reviews = df[df['subcategory'] == subcategory]['review_text']\n",
    "    n_topics = int(min(15, len(reviews)))\n",
    "    svd_transformer, vectorizer, svd_model = create_components(n_topics)\n",
    "    svd_matrix = svd_transformer.fit_transform(reviews)\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for i, topic in enumerate(svd_model.components_):\n",
    "        top_words = [terms[j] for j in topic.argsort()[:-10 - 1:-1]]\n",
    "        \n",
    "        # Calculate topic scores for each review\n",
    "        topic_scores = svd_matrix[:, i]\n",
    "        \n",
    "        # Sort reviews by topic score\n",
    "        sorted_indices = np.argsort(topic_scores)[::-1]\n",
    "        \n",
    "        # Get top 3 representative reviews\n",
    "        top_review_indices = sorted_indices[:3]\n",
    "        rep_reviews = reviews.iloc[top_review_indices].tolist()\n",
    "        \n",
    "        new_row = pd.DataFrame({\n",
    "            'subcategory': [subcategory], \n",
    "            'topic_number': [i], \n",
    "            'top_words': [top_words], \n",
    "            'sample_reviews': [rep_reviews]\n",
    "        })\n",
    "        \n",
    "        lsa_df = pd.concat([lsa_df, new_row], ignore_index=True)\n",
    "\n",
    "lsa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lsa_df to csv\n",
    "lsa_df.to_csv('outputs/lsa_1-2_gram_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster similar topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'clean great use product work sink workgreat year good love',\n",
       " 1: 'use year useyear comet product ive iveuse love usecomet useproduct',\n",
       " 2: 'great work workgreat greatproduct product price productwork greatprice greatclean workgood',\n",
       " 3: 'clean bathroom cleanbathroom kitchen smell comet good tub toilet greatclean',\n",
       " 4: 'good product goodproduct price goodprice greatproduct productclean loveproduct job excellent',\n",
       " 5: 'good work comet cleaner best cleanser stain workgood goodproduct like',\n",
       " 6: 'comet stainless good stainlesssteel usecomet steel like smell clean workgreat',\n",
       " 7: 'best cleaner great bestcleaner price cleaning bathroom comet kitchen bestproduct',\n",
       " 8: 'comet great bar keeper love barkeeper friend keeperfriend price job',\n",
       " 9: 'love product best work comet loveproduct productwork pot bestproduct pan',\n",
       " 10: 'clean cleaner best pot pan potpan useyear year bestcleaner ive',\n",
       " 11: 'stain comet sink water hard job hardwater great remove waterstain',\n",
       " 12: 'love cleaner loveproduct useyear smell loveclean job year loveuse stuff',\n",
       " 13: 'pot pan potpan stain bathroom job remove kitchen water hard',\n",
       " 14: 'like cleaner job scrub soft sink new softscrub look likenew'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove space between 2 gram words in top_words so that when vectorized, they are treated as one entity\n",
    "lsa_df['top_words'] = lsa_df['top_words'].apply(lambda x: [word.replace(' ', '') for word in x])\n",
    "\n",
    "# create dict of subcategories and array of top words joined to one string for each topic\n",
    "lsa_dict = {}\n",
    "for subcategory in lsa_df['subcategory'].unique():\n",
    "    sub_df = lsa_df[lsa_df['subcategory'] == subcategory]\n",
    "    sub_dict = {}\n",
    "    for topic in sub_df['topic_number']:\n",
    "        topic_df = sub_df[sub_df['topic_number'] == topic]\n",
    "        sub_dict[topic] = ' '.join(topic_df['top_words'].values[0])\n",
    "    lsa_dict[subcategory] = sub_dict\n",
    "lsa_dict['ABRASIVE CLEANERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster top words representations for each subcategory\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "n_clusters = 10\n",
    "\n",
    "# kmeans applied to a subcategory, return cluster labels\n",
    "def apply_kmeans(topics_dict, vectorizer, n_clusters):\n",
    "    if len(topics_dict) > n_clusters:\n",
    "        topics_vectorized = vectorizer.fit_transform(topics_dict.values())\n",
    "        kmeans_model = KMeans(n_clusters=n_clusters, random_state=12)\n",
    "        cluster_labels = kmeans_model.fit_predict(topics_vectorized)\n",
    "        return cluster_labels\n",
    "    return None\n",
    "\n",
    "# merge topics in subcategory with the same cluster labels\n",
    "def merge_topics(topics_dict, cluster_labels):\n",
    "    merged_topics = {}\n",
    "    for i in range(len(cluster_labels)):\n",
    "        if cluster_labels[i] not in merged_topics:\n",
    "            merged_topics[cluster_labels[i]] = topics_dict[i]\n",
    "        else:\n",
    "            merged_topics[cluster_labels[i]] += ' ' + topics_dict[i]\n",
    "    return merged_topics\n",
    "\n",
    "# remove duplicate words in merged topics\n",
    "def remove_duplicates(merged_topics):\n",
    "    for label, words in merged_topics.items():\n",
    "        merged_topics[label] = ' '.join(list(set(words.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int32(1): 'work product workgreat use comet useyear year sink iveuse good ive useproduct great clean usecomet love',\n",
       " np.int32(0): 'work productclean product greatclean goodprice greatprice loveproduct excellent goodproduct price job greatproduct productwork good great workgreat workgood',\n",
       " np.int32(6): 'smell toilet kitchen greatclean comet tub cleanbathroom good bathroom clean',\n",
       " np.int32(7): 'work comet cleanser goodproduct best like good cleaner workgood stain',\n",
       " np.int32(8): 'smell clean workgreat comet stainlesssteel like stainless steel good usecomet',\n",
       " np.int32(4): 'bestcleaner kitchen comet friend barkeeper keeperfriend price job best keeper bathroom bestproduct bar great cleaner cleaning love',\n",
       " np.int32(5): 'work bestcleaner ive product comet cleaner loveproduct useyear year potpan best productwork pot bestproduct clean pan love',\n",
       " np.int32(2): 'water remove kitchen comet waterstain hardwater potpan job hard sink bathroom pot great pan stain',\n",
       " np.int32(9): 'smell stuff love loveuse loveproduct year job loveclean cleaner useyear',\n",
       " np.int32(3): 'look soft job scrub sink new like likenew softscrub cleaner'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply kmeans to each subcategory and merge topics with the same cluster labels\n",
    "\n",
    "clustered_dict = {}\n",
    "for subcategory, topics_dict in lsa_dict.items():\n",
    "    cluster_labels = apply_kmeans(topics_dict, vectorizer, n_clusters)\n",
    "    if cluster_labels is not None:\n",
    "        merged_topics = merge_topics(topics_dict, cluster_labels)\n",
    "        remove_duplicates(merged_topics)\n",
    "        clustered_dict[subcategory] = merged_topics\n",
    "    else:\n",
    "        clustered_dict[subcategory] = topics_dict\n",
    "\n",
    "clustered_dict['ABRASIVE CLEANERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clustered_dict to csv\n",
    "clustered_df = pd.DataFrame(columns=['subcategory', 'topic_number', 'top_words'])\n",
    "for subcategory, topics_dict in clustered_dict.items():\n",
    "    for topic, words in topics_dict.items():\n",
    "        new_row = pd.DataFrame({'subcategory': [subcategory], 'topic_number': [topic], 'top_words': [words]})\n",
    "        clustered_df = pd.concat([clustered_df, new_row], ignore_index=True)\n",
    "clustered_df.to_csv('outputs/lsa_1-2_gram_clustered_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'box worksmall work smallcome small drybox dry comedry come'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_dict['BODY CARE HAIR REMOVAL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_processes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

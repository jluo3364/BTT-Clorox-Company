{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from LSA import LSA\n",
    "import pandas as pd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(LSA)\n",
    "from LSA import LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = LSA(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run LSA on one subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# subcat = 'SPRAY CLEANERS BLEACH CLEANERS'\n",
    "# lsa_df = lsa.train_model_subcategory(subcat, verbose=2, calc_similarity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcat_filter = lsa_df['subcategory'] == subcat\n",
    "# lsa_df[subcat_filter & (lsa_df['star_rating']==1)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsa_df = lsa.calculate_similarity_score(subcat)\n",
    "# lsa_df[subcat_filter & (lsa_df['star_rating']==1)].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run LSA on multiple subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LSA model for 1.0 star rating with 160 reviews, 2 topics\n",
      "Finished creating LSA model for 1.0 star rating in 0.52 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 2.0 star rating with 44 reviews, 2 topics\n",
      "Finished creating LSA model for 2.0 star rating in 0.48 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 3.0 star rating with 63 reviews, 2 topics\n",
      "Finished creating LSA model for 3.0 star rating in 0.40 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 4.0 star rating with 95 reviews, 2 topics\n",
      "Finished creating LSA model for 4.0 star rating in 0.39 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 5.0 star rating with 650 reviews, 1 topics\n",
      "Finished creating LSA model for 5.0 star rating in 0.31 seconds\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process chunk 0-1000: 5.48 seconds\n",
      "Time to process chunk 1000-2000: 0.33 seconds\n",
      "Total processing time: 5.81 seconds\n",
      "Finished creating LSA models for FLOOR CLEANERS in 9.26 seconds\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Creating LSA model for 1.0 star rating with 102 reviews, 2 topics\n",
      "Finished creating LSA model for 1.0 star rating in 0.44 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 2.0 star rating with 38 reviews, 2 topics\n",
      "Finished creating LSA model for 2.0 star rating in 0.45 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 3.0 star rating with 57 reviews, 2 topics\n",
      "Finished creating LSA model for 3.0 star rating in 0.50 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 4.0 star rating with 101 reviews, 1 topics\n",
      "Finished creating LSA model for 4.0 star rating in 0.21 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 5.0 star rating with 504 reviews, 1 topics\n",
      "Finished creating LSA model for 5.0 star rating in 0.24 seconds\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process chunk 0-1000: 3.01 seconds\n",
      "Total processing time: 3.01 seconds\n",
      "Finished creating LSA models for TOILET BOWL CLEANERS in 5.74 seconds\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Creating LSA model for 1.0 star rating with 272 reviews, 2 topics\n",
      "Finished creating LSA model for 1.0 star rating in 0.52 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 2.0 star rating with 97 reviews, 2 topics\n",
      "Finished creating LSA model for 2.0 star rating in 0.44 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 3.0 star rating with 165 reviews, 2 topics\n",
      "Finished creating LSA model for 3.0 star rating in 0.63 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 4.0 star rating with 420 reviews, 2 topics\n",
      "Finished creating LSA model for 4.0 star rating in 0.56 seconds\n",
      "\n",
      "--------------------------------------------------\n",
      "Creating LSA model for 5.0 star rating with 3777 reviews, 1 topics\n",
      "Finished creating LSA model for 5.0 star rating in 0.86 seconds\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaluo/Desktop/scrap/text_processes/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process chunk 0-1000: 4.40 seconds\n",
      "Time to process chunk 1000-2000: 3.79 seconds\n",
      "Time to process chunk 2000-3000: 3.87 seconds\n",
      "Time to process chunk 3000-4000: 3.67 seconds\n",
      "Time to process chunk 4000-5000: 3.07 seconds\n",
      "Total processing time: 18.80 seconds\n",
      "Finished creating LSA models for SPRAY CLEANERS BLEACH CLEANERS in 22.68 seconds\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "subcats = ['FLOOR CLEANERS', 'TOILET BOWL CLEANERS', 'SPRAY CLEANERS BLEACH CLEANERS']\n",
    "lsa_df = lsa.train_model(subcats, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_title</th>\n",
       "      <th>proxy_date</th>\n",
       "      <th>retailer</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>review_text</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>topic</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>lsa_topic_number</th>\n",
       "      <th>lsa_top_15_words</th>\n",
       "      <th>lsa_topic_label</th>\n",
       "      <th>lsa_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186158</th>\n",
       "      <td>Clorox</td>\n",
       "      <td>Clorox Clean-Up All Purpose Cleaner with Bleac...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>SPRAY CLEANERS BLEACH CLEANERS</td>\n",
       "      <td>it wasnt my first time purshase and i always b...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Review and recommendation for Clorox cleaning ...</td>\n",
       "      <td>Clorox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>like, spray, kitchen, good, cleaner, work, ble...</td>\n",
       "      <td>\"Great kitchen and bathroom cleaner, effective...</td>\n",
       "      <td>0.352411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172775</th>\n",
       "      <td>Clorox</td>\n",
       "      <td>Clorox Clean-Up All Purpose Cleaner with Bleac...</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>SPRAY CLEANERS BLEACH CLEANERS</td>\n",
       "      <td>i must not have notice this item be from an ou...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Leaking and damaged products upon arrival</td>\n",
       "      <td>Clorox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>like, buy bottle, use, clean, sprayer, bleach,...</td>\n",
       "      <td>Leaky bottle requires cleaning and box alteration</td>\n",
       "      <td>0.480048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175309</th>\n",
       "      <td>Clorox</td>\n",
       "      <td>Clorox Clean-Up All Purpose Cleaner with Bleac...</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>SPRAY CLEANERS BLEACH CLEANERS</td>\n",
       "      <td>good clorox stuff</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Review and recommendation for Clorox cleaning ...</td>\n",
       "      <td>Clorox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>like, spray, kitchen, good, cleaner, work, ble...</td>\n",
       "      <td>\"Great kitchen and bathroom cleaner, effective...</td>\n",
       "      <td>0.251090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111982</th>\n",
       "      <td>Clorox</td>\n",
       "      <td>Clorox Clean-Up All Purpose Cleaner with Bleac...</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>SPRAY CLEANERS BLEACH CLEANERS</td>\n",
       "      <td>clorox clean up leak also palmolive dish soap ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Review and recommendation for Clorox cleaning ...</td>\n",
       "      <td>Clorox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>like, buy bottle, use, clean, sprayer, bleach,...</td>\n",
       "      <td>Leaky bottle requires cleaning and box alteration</td>\n",
       "      <td>0.446679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26261</th>\n",
       "      <td>Clorox</td>\n",
       "      <td>Clorox Clean-Up All Purpose Cleaner with Bleac...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>SPRAY CLEANERS BLEACH CLEANERS</td>\n",
       "      <td>this be handsdown one of my favorite cleaning ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Disinfectant spray recommendations and reviews...</td>\n",
       "      <td>Clorox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>like, spray, kitchen, good, cleaner, work, ble...</td>\n",
       "      <td>\"Great kitchen and bathroom cleaner, effective...</td>\n",
       "      <td>0.509380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand                                      product_title  proxy_date  \\\n",
       "186158  Clorox  Clorox Clean-Up All Purpose Cleaner with Bleac...  2023-02-06   \n",
       "172775  Clorox  Clorox Clean-Up All Purpose Cleaner with Bleac...  2023-04-10   \n",
       "175309  Clorox  Clorox Clean-Up All Purpose Cleaner with Bleac...  2023-03-27   \n",
       "111982  Clorox  Clorox Clean-Up All Purpose Cleaner with Bleac...  2023-10-02   \n",
       "26261   Clorox  Clorox Clean-Up All Purpose Cleaner with Bleac...  2024-04-22   \n",
       "\n",
       "       retailer  category                     subcategory  \\\n",
       "186158   Kroger  CLEANING  SPRAY CLEANERS BLEACH CLEANERS   \n",
       "172775  Walmart  CLEANING  SPRAY CLEANERS BLEACH CLEANERS   \n",
       "175309   Amazon  CLEANING  SPRAY CLEANERS BLEACH CLEANERS   \n",
       "111982  Walmart  CLEANING  SPRAY CLEANERS BLEACH CLEANERS   \n",
       "26261   Walmart  CLEANING  SPRAY CLEANERS BLEACH CLEANERS   \n",
       "\n",
       "                                              review_text  star_rating  \\\n",
       "186158  it wasnt my first time purshase and i always b...          5.0   \n",
       "172775  i must not have notice this item be from an ou...          2.0   \n",
       "175309                                  good clorox stuff          5.0   \n",
       "111982  clorox clean up leak also palmolive dish soap ...          2.0   \n",
       "26261   this be handsdown one of my favorite cleaning ...          5.0   \n",
       "\n",
       "                                                    topic brand_type  \\\n",
       "186158  Review and recommendation for Clorox cleaning ...     Clorox   \n",
       "172775          Leaking and damaged products upon arrival     Clorox   \n",
       "175309  Review and recommendation for Clorox cleaning ...     Clorox   \n",
       "111982  Review and recommendation for Clorox cleaning ...     Clorox   \n",
       "26261   Disinfectant spray recommendations and reviews...     Clorox   \n",
       "\n",
       "        lsa_topic_number                                   lsa_top_15_words  \\\n",
       "186158               0.0  like, spray, kitchen, good, cleaner, work, ble...   \n",
       "172775               0.0  like, buy bottle, use, clean, sprayer, bleach,...   \n",
       "175309               0.0  like, spray, kitchen, good, cleaner, work, ble...   \n",
       "111982               0.0  like, buy bottle, use, clean, sprayer, bleach,...   \n",
       "26261                0.0  like, spray, kitchen, good, cleaner, work, ble...   \n",
       "\n",
       "                                          lsa_topic_label  \\\n",
       "186158  \"Great kitchen and bathroom cleaner, effective...   \n",
       "172775  Leaky bottle requires cleaning and box alteration   \n",
       "175309  \"Great kitchen and bathroom cleaner, effective...   \n",
       "111982  Leaky bottle requires cleaning and box alteration   \n",
       "26261   \"Great kitchen and bathroom cleaner, effective...   \n",
       "\n",
       "        lsa_similarity_score  \n",
       "186158              0.352411  \n",
       "172775              0.480048  \n",
       "175309              0.251090  \n",
       "111982              0.446679  \n",
       "26261               0.509380  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_df[lsa_df['subcategory'].isin(subcats)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>lsa_topic_label</th>\n",
       "      <th>lsa_similarity_score</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Don't waste money on low-quality brush and wa...</td>\n",
       "      <td>0.230237</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Waste money on a bad mop that doesn't clean t...</td>\n",
       "      <td>0.279589</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"Expectations unmet: car seat doesn't work, pe...</td>\n",
       "      <td>0.293354</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"Spray cleaner doesn't work as expected\"</td>\n",
       "      <td>0.289269</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Effective carpet cleaning with pleasant odor\"</td>\n",
       "      <td>0.346937</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Product breaks easily, requires frequent repla...</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Effortless mopping with O-Cedar's easy spin m...</td>\n",
       "      <td>0.487825</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Good carpet, easy job, great clean\"</td>\n",
       "      <td>0.267137</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\"Easy, effective, and great for carpet cleaning\"</td>\n",
       "      <td>0.362122</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    lsa_topic_label  \\\n",
       "0          1.0  \"Don't waste money on low-quality brush and wa...   \n",
       "1          1.0  \"Waste money on a bad mop that doesn't clean t...   \n",
       "2          2.0  \"Expectations unmet: car seat doesn't work, pe...   \n",
       "3          2.0           \"Spray cleaner doesn't work as expected\"   \n",
       "4          3.0     \"Effective carpet cleaning with pleasant odor\"   \n",
       "5          3.0  Product breaks easily, requires frequent repla...   \n",
       "6          4.0  \"Effortless mopping with O-Cedar's easy spin m...   \n",
       "7          4.0               \"Good carpet, easy job, great clean\"   \n",
       "8          5.0   \"Easy, effective, and great for carpet cleaning\"   \n",
       "\n",
       "   lsa_similarity_score  count  \n",
       "0              0.230237     16  \n",
       "1              0.279589    144  \n",
       "2              0.293354      5  \n",
       "3              0.289269     39  \n",
       "4              0.346937     45  \n",
       "5              0.240547     18  \n",
       "6              0.487825     12  \n",
       "7              0.267137     83  \n",
       "8              0.362122    650  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_processes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
